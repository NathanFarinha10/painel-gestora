import streamlit as st
import pandas as pd
import google.generativeai as genai
import PyPDF2
from io import BytesIO, StringIO
import datetime
import json
import requests
import base64 

# --- CONFIGURA√á√ÉO E VALIDA√á√ÉO DA CHAVE API ---
st.set_page_config(
    page_title="Market Intelligence Platform",
    layout="wide",
    initial_sidebar_state="expanded"
)

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    st.error("Chave da API do Gemini n√£o configurada! Adicione `GEMINI_API_KEY` nos Secrets da aplica√ß√£o.")
    st.stop()

# Token de Acesso do GitHub
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    st.error("Token do GitHub n√£o configurado! Adicione `GITHUB_TOKEN` nos Secrets para a automa√ß√£o funcionar.")
    st.stop()

# --- CONFIGURA√á√ÉO DO GITHUB (VOC√ä PRECISA EDITAR ISSO) ---
REPO_OWNER = "NathanFarinha10"  # Ex: "fulanodasilva"
REPO_NAME = "painel-gestora"       # Ex: "painel-gestora"
FILE_PATH = "market_intelligence_db.csv"
GITHUB_API_URL = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"

# --- FUN√á√ïES CORE (REATORADAS) ---

# A fun√ß√£o de extrair texto do PDF permanece a mesma
@st.cache_data
def extrair_texto_pdf(arquivo_pdf_bytes, nome_arquivo):
    try:
        texto_completo = ""
        leitor_pdf = PyPDF2.PdfReader(BytesIO(arquivo_pdf_bytes))
        for pagina in leitor_pdf.pages:
            texto_completo += pagina.extract_text() or ""
        return texto_completo
    except Exception as e:
        st.error(f"Erro ao ler o arquivo PDF '{nome_arquivo}': {e}")
        return None

# Fun√ß√£o de extra√ß√£o com IA foi refatorada para ser mais segura e n√£o ter widgets
@st.cache_data
def extrair_dados_com_ia(_texto_pdf):
    """
    Chama a IA para extrair dados.
    Retorna uma tupla: (dados, erro, resposta_bruta).
    - Em caso de sucesso: (lista_de_dicionarios, None, None)
    - Em caso de falha: (None, mensagem_de_erro, resposta_da_ia)
    """
    model = genai.GenerativeModel('gemini-1.5-flash')
    prompt = """
    Analise o texto do relat√≥rio de mercado a seguir. Sua tarefa √© extrair as vis√µes de investimento.
    Retorne sua resposta como uma string JSON v√°lida, contendo uma lista de objetos.
    Cada objeto deve ter estritamente as seguintes chaves: "data_relatorio", "nome_gestora", "pais_regiao", "classe_ativo", "subclasse_ativo", "visao_sentimento", "tese_principal".
    - "visao_sentimento" deve ser apenas "Otimista", "Neutro" ou "Pessimista".
    - Se uma informa√ß√£o n√£o for encontrada, use um campo vazio "".
    - Se nenhuma vis√£o de investimento for encontrada no texto, retorne uma lista vazia [].
    O texto para an√°lise √©:
    ---
    {}
    ---
    """.format(_texto_pdf)
    
    try:
        response = model.generate_content(prompt)
        # Limpa a resposta para garantir que seja um JSON v√°lido
        clean_response = response.text.strip().replace("```json", "").replace("```", "").strip()
        
        # Usa json.loads(), que √© muito mais seguro que eval()
        dados_extraidos = json.loads(clean_response)
        
        if isinstance(dados_extraidos, list):
            return dados_extraidos, None, None
        else:
            return None, "A IA n√£o retornou uma lista no JSON.", clean_response
            
    except json.JSONDecodeError:
        return None, "A IA retornou um JSON inv√°lido. N√£o foi poss√≠vel decodificar.", response.text
    except Exception as e:
        return None, f"Ocorreu um erro inesperado: {e}", response.text

def update_csv_on_github(novas_linhas_csv):
    """
    Fun√ß√£o para buscar o CSV no GitHub, adicionar novas linhas e salvar de volta.
    """
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    # 1. Obter o conte√∫do atual do arquivo e seu SHA (obrigat√≥rio para atualiza√ß√£o)
    try:
        response = requests.get(GITHUB_API_URL, headers=headers)
        response.raise_for_status() # Lan√ßa um erro se a requisi√ß√£o falhar (ex: 404 Not Found)
        
        file_data = response.json()
        content_base64 = file_data["content"]
        sha = file_data["sha"]
        
        # 2. Decodificar o conte√∫do de Base64 para texto
        conteudo_atual = base64.b64decode(content_base64).decode("utf-8")
        
        # 3. Adicionar as novas linhas ao conte√∫do existente
        conteudo_final = conteudo_atual + "\n" + novas_linhas_csv.strip()
        
        # 4. Codificar o novo conte√∫do de volta para Base64
        novo_conteudo_base64 = base64.b64encode(conteudo_final.encode("utf-8")).decode("utf-8")
        
        # 5. Preparar os dados para a requisi√ß√£o de atualiza√ß√£o (PUT)
        data = {
            "message": f"Atualiza√ß√£o autom√°tica do DB via Streamlit App - {datetime.date.today()}",
            "content": novo_conteudo_base64,
            "sha": sha # Informa ao GitHub qual vers√£o do arquivo estamos atualizando
        }
        
        update_response = requests.put(GITHUB_API_URL, headers=headers, json=data)
        update_response.raise_for_status() # Lan√ßa um erro se a atualiza√ß√£o falhar
        
        return True, "Arquivo atualizado com sucesso no GitHub!"
        
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            return False, f"Erro: Arquivo '{FILE_PATH}' n√£o encontrado. Verifique o caminho e nome do reposit√≥rio."
        return False, f"Erro de HTTP ao comunicar com o GitHub: {e}"
    except Exception as e:
        return False, f"Ocorreu um erro inesperado na automa√ß√£o: {e}"

# --- NAVEGA√á√ÉO E P√ÅGINAS ---

st.sidebar.title("Navega√ß√£o")
pagina = st.sidebar.radio("Escolha uma p√°gina", ["Macro View", "Assets View", "Admin: Processar Relat√≥rio"])

try:
    df = pd.read_csv("market_intelligence_db.csv")
except FileNotFoundError:
    st.sidebar.error("Arquivo 'market_intelligence_db.csv' n√£o encontrado.")
    st.stop()

if pagina == "Macro View":
    st.title("üåé Macro View - An√°lise por Pa√≠s/Regi√£o")
    paises = df['pais_regiao'].dropna().unique()
    pais_selecionado = st.selectbox("Selecione uma Regi√£o", sorted(paises))
    if pais_selecionado:
        df_filtrado = df[df['pais_regiao'] == pais_selecionado]
        st.subheader(f"Vis√µes para {pais_selecionado}")
        if df_filtrado.empty:
            st.info("Nenhuma vis√£o encontrada para esta regi√£o.")
        else:
            for index, row in df_filtrado.iterrows():
                # **IN√çCIO DO BLOCO CORRIGIDO**
                with st.container(border=True):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**Gestora:** {row['nome_gestora']}")
                        st.markdown(f"**Ativo:** {row['classe_ativo']} ({row.get('subclasse_ativo', 'N/A')})")
                        st.info(f"**Tese:** {row['tese_principal']}")
                    with col2:
                        sentimento = row['visao_sentimento']
                        if sentimento == 'Otimista':
                            st.success(f"**Vis√£o: {sentimento}**")
                        elif sentimento == 'Pessimista':
                            st.error(f"**Vis√£o: {sentimento}**")
                        else:
                            st.warning(f"**Vis√£o: {sentimento}**")
                        st.caption(f"Fonte: {row['fonte_documento']}")
                # **FIM DO BLOCO CORRIGIDO**

elif pagina == "Assets View":
    st.title("üìä Assets View - An√°lise por Classe de Ativo")
    classes = df['classe_ativo'].dropna().unique()
    classe_selecionada = st.selectbox("Selecione uma Classe de Ativo", sorted(classes))
    if classe_selecionada:
        df_filtrado = df[df['classe_ativo'] == classe_selecionada]
        st.subheader(f"Vis√µes para {classe_selecionada}")
        if df_filtrado.empty:
            st.info("Nenhuma vis√£o encontrada para esta classe de ativo.")
        else:
            for index, row in df_filtrado.iterrows():
                # **IN√çCIO DO BLOCO CORRIGIDO**
                with st.container(border=True):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**Gestora:** {row['nome_gestora']}")
                        st.markdown(f"**Regi√£o:** {row['pais_regiao']}")
                        st.info(f"**Tese:** {row['tese_principal']}")
                    with col2:
                        sentimento = row['visao_sentimento']
                        if sentimento == 'Otimista':
                            st.success(f"**Vis√£o: {sentimento}**")
                        elif sentimento == 'Pessimista':
                            st.error(f"**Vis√£o: {sentimento}**")
                        else:
                            st.warning(f"**Vis√£o: {sentimento}**")
                        st.caption(f"Fonte: {row['fonte_documento']}")
                # **FIM DO BLOCO CORRIGIDO**

elif pagina == "Admin: Processar Relat√≥rio":
    st.title("‚öôÔ∏è Admin: Extrair Dados e Atualizar a Base")

    uploaded_file = st.file_uploader("1. Fa√ßa o upload do relat√≥rio em PDF", type="pdf")

    if uploaded_file is not None:
        if st.button("Analisar e Salvar no GitHub"):
            
            with st.spinner("Lendo o PDF..."):
                pdf_bytes = uploaded_file.getvalue()
                texto_pdf = extrair_texto_pdf(pdf_bytes, uploaded_file.name)
            
            if texto_pdf:
                with st.spinner("Analisando com IA e preparando dados..."):
                    dados, erro, resposta_bruta = extrair_dados_com_ia(texto_pdf)
                
                if erro:
                    st.error(f"**Falha na Extra√ß√£o:** {erro}")
                    st.text_area("Resposta bruta da IA:", resposta_bruta, height=200)
                elif not dados:
                     st.warning("Nenhuma vis√£o de investimento foi encontrada no documento.")
                else:
                    st.success("Dados extra√≠dos com sucesso pela IA!")
                    df_novos_dados = pd.DataFrame(dados)
                    df_novos_dados['data_extracao'] = datetime.date.today().strftime("%Y-%m-%d")
                    df_novos_dados['fonte_documento'] = uploaded_file.name
                    
                    # Preparar as novas linhas em formato CSV
                    output = StringIO()
                    df_novos_dados.to_csv(output, index=False, header=False)
                    csv_string = output.getvalue()
                    
                    with st.spinner("Salvando dados no GitHub..."):
                        sucesso, mensagem = update_csv_on_github(csv_string)
                    
                    if sucesso:
                        st.success(mensagem)
                        st.balloons()
                        st.info("A aplica√ß√£o ir√° recarregar para exibir os novos dados. Atualize a p√°gina se necess√°rio.")
                    else:
                        st.error(f"**Falha ao salvar no GitHub:** {mensagem}")
